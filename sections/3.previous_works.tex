\section{Previosu Works}\label{sec:previous_works}


During the Emmy Noether Programme I will chart the normative predictome by estimating the architecture or function of one brain region from the collection of other brain regions across modalities for one of the largest reference cohorts assembled to date incorporating relevant covariates and confounds into different machine learning models. This approach extends the use of our earlier developed normative modelling framework and has shown superior performance in preliminary comparisons (Figure 2 A). As a proof of principle we estimated cortical thickness from thalamic volume in a small sample of 500 individuals and detected a plausible predicted pattern (Figure 2 B) that mimics the established relationship between the cortex and different thalamic nuclei 14. To develop this approach further, I will pursue the following strategy. First, I will assemble a large-scale database for model development in close collaboration with my local, national, and international partners. Second, I will implement machine learning methods charting the normative predictome. More concretely, I will estimate the cortical predictome for which I will predict the structure of the cortex from different subcortical brain regions. In addition, I will develop a method to estimate the lateral predictome, for which I will predict the right side of the brain from a multivariate estimate of the left and vice versa improving current univariate approaches of laterality assessment. Furthermore, I will estimate the multimodal predictome for which I will predict one imaging modality from another. Third, I will validate the predictome based normative models against clinical phenotypes. The availability of a large database allows for extensive validations against different disorders and diseases. Concretely, the estimated predictomes will be used to map inter-individual differences of people with the same illness. Fourth, I will translate our models to estimate longitudinal change. Clinical trials are generally designed to detect effects of treatments that occur in terms of months, weeks, hours, minutes or even seconds. The approach proposed here will be able to capture predictive patterns between brain regions at high temporal precision. The deeply phenotyped ABCD dataset 15, which is a large scale population based dataset of children and adolescents which are consulted about every two years, is an excellent resource for initial longitudinal validations. Further, data from clinical trials gathered by partnering consortia will be included which contain clinical information (e.g., TOP, EU-AIMS, NeuroImage).

My previous work provides an outstanding basis for the here proposed research 9,16,17. Using age-based normative models I have shown a high degree of heterogeneity in clinical groups (Figure 1). Recently, my colleagues and I modelled cognition within the normative modelling framework and linked this to polygenic risk scores 18, and worked on scaling age-based normative models to populations of more than 50k individuals19, developed deep learning technology for normative modelling in the context of aging 20 and integrated it into the PCNtoolkit, a python based statistics and machine learning toolkit for normative modelling 16. Currently, I focus my work on deep covariate embedding, for which we use the abstraction layers of a neural network as embedding space for a normative model. This architecture allows us to identify individual level profiles of deviation from minimally preprocessed brain imaging data (Figure 3). Combined this work forms the basis for my research in Tübingen on the normative predictome. My background and expertise in relevant research domains in combination with excellent partners and an embedding in an outstanding research environment at the University of Tübingen as well as the availability of large scale datasets contributes to the feasability and exellence of the proposed work.
